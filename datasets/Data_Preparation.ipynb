{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "PATH = '/path/to/your/data/'\n",
    "\n",
    "mydateparser = lambda x: dt.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "account_id_type = dict()\n",
    "\n",
    "account_id_type = {'account_id': str,\n",
    "                   'post_id': str}\n",
    "\n",
    "fb_type = {'account_id': str,\n",
    "           'account_username': str,\n",
    "           'fan': str,\n",
    "           'post_id': str}\n",
    "\n",
    "#Facebook\n",
    "df_fb1 = pd.read_csv(PATH+\"Facebook_Data_Q1.csv\", dtype=fb_type, parse_dates=['created_at'], date_parser=mydateparser)\n",
    "df_fb2 = pd.read_csv(PATH+\"Facebook_Data_Q2.csv\", dtype=fb_type, parse_dates=['created_at'], date_parser=mydateparser)\n",
    "df_fb3 = pd.read_csv(PATH+\"Facebook_Data_Q3.csv\", dtype=fb_type, parse_dates=['created_at'], date_parser=mydateparser)\n",
    "df_fb4 = pd.read_csv(PATH+\"Facebook_Data_Q4.csv\", dtype=fb_type, parse_dates=['created_at'], date_parser=mydateparser)\n",
    "df_fb = df_fb1.append(df_fb2, ignore_index = True)\n",
    "df_fb = df_fb.append(df_fb3, ignore_index = True)\n",
    "df_fb = df_fb.append(df_fb4, ignore_index = True)\n",
    "\n",
    "#IG, TW, YT\n",
    "df_ig = pd.read_csv(PATH+\"Instagram_Data.csv\", dtype=account_id_type, parse_dates=['created_at'], date_parser=mydateparser)\n",
    "df_tw = pd.read_csv(PATH+\"Twitter_Data.csv\", dtype=account_id_type, parse_dates=['created_at'], date_parser=mydateparser)\n",
    "df_yt = pd.read_csv(PATH+\"YouTube_Data.csv\", dtype=account_id_type, parse_dates=['created_at'], date_parser=mydateparser)\n",
    "\n",
    "\n",
    "# fb_cat_fanrange_funnel\n",
    "df_cat_fanrange = pd.read_csv(PATH+'FB_cat_fanrange_funnel.csv', encoding='utf-8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4087162 entries, 0 to 4087238\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count    Dtype         \n",
      "---  ------                --------------    -----         \n",
      " 0   post_id               4087162 non-null  object        \n",
      " 1   channel               4087162 non-null  object        \n",
      " 2   account_id            4087162 non-null  object        \n",
      " 3   account_username      832211 non-null   object        \n",
      " 4   account_display_name  4080641 non-null  object        \n",
      " 5   link                  4087047 non-null  object        \n",
      " 6   created_at            4087162 non-null  datetime64[ns]\n",
      " 7   message               2647164 non-null  object        \n",
      " 8   new_engagement        4087162 non-null  int64         \n",
      " 9   positive              4087162 non-null  int64         \n",
      " 10  neutral               4087162 non-null  int64         \n",
      " 11  negative              4087162 non-null  int64         \n",
      " 12  fan                   4087162 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(5), object(7)\n",
      "memory usage: 436.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# calculate new engagement each channel\n",
    "df_fb['new_engagement'] = df_fb['engagement']\n",
    "df_ig['new_engagement'] = df_ig[['like', 'comment','view','share_on_facebook']].apply(sum, axis=1)\n",
    "df_tw['new_engagement'] = df_tw[['favorite', 'retweet','share_on_facebook','reply']].apply(sum, axis=1)\n",
    "df_yt['new_engagement'] = df_yt[['like', 'dislike','favorite','comment','view','share_on_facebook']].apply(sum, axis=1)\n",
    "\n",
    "# combine 14 column of 4 channel to 1 dataframe\n",
    "selected_column = ['post_id', 'channel', 'account_id', \\\n",
    "    'account_username', 'account_display_name', 'link', \\\n",
    "    'created_at', 'message', 'new_engagement', 'positive', 'neutral', 'negative', 'fan']\n",
    "\n",
    "df_all = df_fb[selected_column].append(df_ig[selected_column], ignore_index = True)\n",
    "df_all = df_all.append(df_tw[selected_column], ignore_index = True)\n",
    "df_all = df_all.append(df_yt[selected_column], ignore_index = True)\n",
    "\n",
    "\n",
    "# Drop row that has '\\N'\n",
    "df_all = df_all[df_all['fan'] != '\\\\N']\n",
    "\n",
    "# change 'fan' column to int\n",
    "df_all['fan'] = df_all['fan'].astype('int64')\n",
    "df_all.info(verbose=True, show_counts=True)\n",
    "\n",
    "\n",
    "# create dataframe that contain account_id, account_display_name\n",
    "df_acc = df_all[['account_id','account_display_name']]\n",
    "df_acc = df_acc.drop_duplicates(subset='account_id', keep='last')\n",
    "\n",
    "# threshold for time range\n",
    "bins = list(range(0,25))\n",
    "\n",
    "time_range = [\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\", \"08:00\", \"09:00\",\n",
    "              \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\", \"16:00\", \"17:00\", \"18:00\", \"19:00\", \n",
    "              \"20:00\", \"21:00\", \"22:00\", \"23:00\"]\n",
    "\n",
    "# create new column to tell created time of each post?\n",
    "df_all['post_time_range'] = pd.cut(df_all.created_at.dt.hour,       \n",
    "                             bins, \n",
    "                             labels=time_range,  \n",
    "                             right=False)\n",
    "\n",
    "# create day column\n",
    "df_all['day'] = df_all['created_at'].dt.day_name()\n",
    "\n",
    "# Define column 'day' as categories type which order the seq of day name\n",
    "cats = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type = CategoricalDtype(categories=cats, ordered=True)\n",
    "df_all['day'] = df_all['day'].astype(cat_type)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/_h829tpn5zq19y29l_cbntzm0000gn/T/ipykernel_69379/3173307639.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_all_account.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# export file for mapping account with file Account_Mapping_NoCat.csv by using vlookup in excel  \n",
    "df_all_account = df_all[['channel', 'account_id', 'account_username', 'account_display_name']]\n",
    "df_all_account.drop_duplicates(inplace=True)\n",
    "df_all_account.to_csv('df_all_account.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zr/_h829tpn5zq19y29l_cbntzm0000gn/T/ipykernel_69379/48749063.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_view_vs_fan['month'] = df_view_vs_fan['created_at'].dt.month_name()\n",
      "/var/folders/zr/_h829tpn5zq19y29l_cbntzm0000gn/T/ipykernel_69379/48749063.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_view_vs_fan['month'] = df_view_vs_fan['month'].astype(cat_type)\n",
      "/var/folders/zr/_h829tpn5zq19y29l_cbntzm0000gn/T/ipykernel_69379/48749063.py:14: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_view_vs_fan = df_view_vs_fan.groupby(['account_display_name', 'month'])['view', 'fan'].agg({'view':'sum', 'fan': 'count'}).reset_index()\n",
      "/var/folders/zr/_h829tpn5zq19y29l_cbntzm0000gn/T/ipykernel_69379/48749063.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_yt_fan['month'] = df_yt_fan['created_at'].dt.month_name()\n",
      "/var/folders/zr/_h829tpn5zq19y29l_cbntzm0000gn/T/ipykernel_69379/48749063.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_yt_fan['month'] = df_yt_fan['month'].astype(cat_type)\n"
     ]
    }
   ],
   "source": [
    "#Animated scatter plotter for avg view and fan\n",
    "df_view_vs_fan = df_yt[['account_display_name', 'view', 'created_at', 'fan']]\n",
    "\n",
    "# create month column\n",
    "df_view_vs_fan['month'] = df_view_vs_fan['created_at'].dt.month_name()\n",
    "\n",
    "month_cats = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type = CategoricalDtype(categories=month_cats, ordered=True)\n",
    "df_view_vs_fan['month'] = df_view_vs_fan['month'].astype(cat_type)\n",
    "\n",
    "\n",
    "# Get avg_view\n",
    "df_view_vs_fan = df_view_vs_fan.groupby(['account_display_name', 'month'])['view', 'fan'].agg({'view':'sum', 'fan': 'count'}).reset_index()\n",
    "df_view_vs_fan = df_view_vs_fan.rename(columns={'fan':'count'})\n",
    "df_view_vs_fan['avg_view'] = df_view_vs_fan['view'] // df_view_vs_fan['count']\n",
    "\n",
    "df_yt_fan = df_yt[['account_display_name', 'created_at', 'fan']]\n",
    "\n",
    "# create month column\n",
    "df_yt_fan['month'] = df_yt_fan['created_at'].dt.month_name()\n",
    "\n",
    "month_cats = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type = CategoricalDtype(categories=month_cats, ordered=True)\n",
    "df_yt_fan['month'] = df_yt_fan['month'].astype(cat_type)\n",
    "\n",
    "# Get latest fan\n",
    "df_yt_fan = df_yt_fan.sort_values(by=['account_display_name', 'month', 'created_at']).groupby(['account_display_name', 'month']).tail(1)\n",
    "\n",
    "\n",
    "# Merge dataframe\n",
    "df_view_vs_fan = df_view_vs_fan.merge(right=df_yt_fan, left_on=['account_display_name', 'month'], right_on=['account_display_name', 'month'], how='inner')\n",
    "\n",
    "# create column type_fan\n",
    "def classify_fan_amount(row):\n",
    "\n",
    "    if row['fan'] >= 100000 and row['fan'] <= 999999:\n",
    "        type_fan = 'Silver'\n",
    "    elif row['fan'] > 999999 and row['fan'] <= 10000000:\n",
    "        type_fan = 'Gold'\n",
    "    elif row['fan'] > 10000000:\n",
    "        type_fan = 'Diamond'\n",
    "    else:\n",
    "        type_fan = 'NA'\n",
    "\n",
    "    return type_fan\n",
    "\n",
    "df_view_vs_fan['type_fan'] = df_view_vs_fan.apply(classify_fan_amount, axis=1)\n",
    "df_view_vs_fan = df_view_vs_fan.loc[df_view_vs_fan['type_fan'] != 'NA']\n",
    "\n",
    "fan_cats = ['Diamond', 'Gold', 'Silver', 'Filtered by dropdown']\n",
    "fan_type = CategoricalDtype(categories=fan_cats, ordered=True)\n",
    "df_view_vs_fan['type_fan'] = df_view_vs_fan['type_fan'].astype(fan_type)\n",
    "\n",
    "df_view_vs_fan = df_view_vs_fan.sort_values(by=['type_fan', 'account_display_name', 'month'])\n",
    "\n",
    "# add missing month name each account id by using groupby categorical column(month)\n",
    "df_view_vs_fan = df_view_vs_fan.groupby(['account_display_name', 'month']).agg(lambda x:x).reset_index()\n",
    "df_view_vs_fan.loc[:,['view', 'count', 'avg_view', 'created_at', 'fan']] = df_view_vs_fan.loc[:,['view', 'count', 'avg_view', 'created_at', 'fan']].fillna(0)\n",
    "df_view_vs_fan.loc[:,['type_fan']] = df_view_vs_fan.loc[:,['type_fan']].fillna('Silver')\n",
    "\n",
    "df_view_vs_fan = df_view_vs_fan.sort_values(by=['type_fan', 'account_display_name', 'month'])\n",
    "\n",
    "# Export to csv file\n",
    "df_view_vs_fan.to_csv('df_view_vs_fan.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line chart fan in each month of each account ID\n",
    "df_map_all_platform = pd.read_csv(PATH+'Account_mapping_v2.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "df_fan_each_month = df_all[['channel', 'account_id', 'created_at', 'fan']].merge(right=df_map_all_platform[['account_id', 'mapped_name']], \n",
    "                                                                                right_on='account_id',\n",
    "                                                                                left_on='account_id',\n",
    "                                                                                how='inner')[['mapped_name', 'channel', 'created_at', 'fan']]\n",
    "\n",
    "# create month column\n",
    "df_fan_each_month['month'] = df_fan_each_month['created_at'].dt.month_name()\n",
    "\n",
    "df_fan_each_month = df_fan_each_month[['mapped_name', 'channel', 'month', 'created_at', 'fan']]\n",
    "\n",
    "month_cats = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type = CategoricalDtype(categories=month_cats, ordered=True)\n",
    "df_fan_each_month['month'] = df_fan_each_month['month'].astype(cat_type)\n",
    "\n",
    "\n",
    "# get lastest fan from last date of each month\n",
    "df_fan_each_month = df_fan_each_month.sort_values(by=['mapped_name', 'channel', 'month', 'created_at'], ascending=True).groupby(['mapped_name', 'channel', 'month']).tail(1)\n",
    "\n",
    "# add missing month name each account id by using groupby categorical column(month)\n",
    "df_fan_each_month = df_fan_each_month.groupby(['mapped_name', 'channel', 'month'])['fan'].agg(lambda x:x).reset_index()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objs import Layout\n",
    "\n",
    "# data for drop down list to filter mapped_name\n",
    "df_unique_name_channel= df_fan_each_month[['mapped_name', 'channel']].drop_duplicates()\n",
    "\n",
    "# export to csv\n",
    "df_unique_name_channel.to_csv('df_unique_name_channel.csv', encoding='utf-8')\n",
    "df_fan_each_month.to_csv('df_fan_each_month.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart Fan+Engagement\n",
    "df_engagement_fan = df_all.loc[:, ['channel', 'account_id', 'created_at', 'new_engagement', 'fan']]\n",
    "\n",
    "selected_column = ['channel', 'account_id', 'new_engagement', 'fan']\n",
    "\n",
    "# sum new_engagement & count post each account\n",
    "df_avg_engagement = df_engagement_fan[selected_column].groupby(['channel', 'account_id']).agg({'new_engagement': 'sum', 'fan': 'count'}).reset_index()\n",
    "df_avg_engagement = df_avg_engagement.rename(columns={'fan':'post_count'})\n",
    "\n",
    "# create average engagement per post \n",
    "df_avg_engagement['value'] = df_avg_engagement['new_engagement'] / df_avg_engagement['post_count']\n",
    "df_avg_engagement['type_value'] = 'average_engagement_per_post'\n",
    "\n",
    "\n",
    "# get the latest fan amount each account\n",
    "df_fan_by_account = df_engagement_fan.sort_values(by=['channel', 'account_id', 'created_at'], ascending=False).drop_duplicates(subset=['channel', 'account_id'])\n",
    "df_fan_by_account['type_value'] = 'fan'\n",
    "df_fan_by_account = df_fan_by_account.rename(columns={'fan':'value'})\n",
    "\n",
    "# find 'total' = average engagement + fan in order to sort data\n",
    "df_total = df_avg_engagement.merge(df_fan_by_account[['account_id', 'value']], left_on='account_id', right_on='account_id')\n",
    "df_total['total'] = df_total['value_x'] + df_total['value_y']\n",
    "\n",
    "# combine df_avg_engagement + df_fan_by_account\n",
    "df_channel_account_top_engagement = df_avg_engagement[['channel', 'account_id', 'type_value', 'value']].append(df_fan_by_account[['channel', 'account_id','type_value','value']], ignore_index=True )\n",
    "\n",
    "# add 'total' column to df_channel_account_top_engagement\n",
    "df_channel_account_top_engagement = df_channel_account_top_engagement.merge(df_total[['account_id', 'total']], left_on='account_id', right_on='account_id', how='left')\n",
    "\n",
    "# add 'account_display_name' column to df_channel_account_top_engagement\n",
    "df_channel_account_top_engagement = df_channel_account_top_engagement.merge(df_acc, left_on='account_id', right_on='account_id', how='left')\n",
    "\n",
    "# sort value\n",
    "df_channel_account_top_engagement = df_channel_account_top_engagement.sort_values(by=['channel', 'total', 'type_value'], ascending=False)\n",
    "df_channel_account_top_engagement\n",
    "\n",
    "# Export to csv\n",
    "df_channel_account_top_engagement.to_csv('df_channel_account_top_engagement.csv', index=False ,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Heatmap chart day vs time\n",
    "df_channel_posttime_engagement = df_all.loc[:, ['channel', 'day', 'post_time_range', 'new_engagement']]\n",
    "\n",
    "df_channel_posttime_engagement['post_time_range'] = df_channel_posttime_engagement['post_time_range'].astype(str)\n",
    "df_channel_posttime_engagement = df_channel_posttime_engagement.groupby(['channel', 'day', 'post_time_range']).agg('sum').reset_index()\n",
    "\n",
    "# create pivot table to be input of heatmap\n",
    "df_day_vs_time = pd.pivot_table(df_channel_posttime_engagement, index=['channel', 'day'], columns='post_time_range', values='new_engagement')\n",
    "\n",
    "# reset index before export to csv\n",
    "df_day_vs_time = df_day_vs_time.rename_axis(None, axis=1).reset_index()\n",
    "\n",
    "df_day_vs_time.to_csv('df_day_vs_time.csv', index=False ,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donut chart popular by engagement and influencer\n",
    "# create pivot table to be input of donut chart\n",
    "df_channel_engagement = df_all.loc[:, ['channel', 'account_id', 'new_engagement']]\n",
    "\n",
    "df_channel_engagement = df_channel_engagement.groupby(['channel']).agg({'account_id': pd.Series.nunique, 'new_engagement': 'sum'}).sort_index(ascending=True).reset_index()\n",
    "\n",
    "df_channel_engagement\n",
    "df_channel_engagement.to_csv('df_channel_engagement.csv', index=False ,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart Video vs Image posting\n",
    "df_ig_img_video = df_ig.loc[:, ['post_type', 'new_engagement', 'channel']]\n",
    "\n",
    "df_ig_img_video = df_ig_img_video.groupby('post_type').agg({'new_engagement': 'sum', 'channel': 'count'}).reset_index()\n",
    "df_ig_img_video = df_ig_img_video.rename(columns={'channel': 'post_count'})\n",
    "df_ig_img_video['avg_engagement'] =  df_ig_img_video['new_engagement'] / df_ig_img_video['post_count']\n",
    "df_ig_img_video = df_ig_img_video.sort_values(by='avg_engagement',ascending=False)\n",
    "\n",
    "df_ig_img_video.to_csv('df_ig_img_video.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funnel chart for purchasing intention\n",
    "df_fb_funnel = df_fb.loc[:, ['account_id', 'new_engagement', 'reaction', 'like', 'love', 'wow', 'haha', 'share', 'comment', 'tag_friend', 'purchase_intention']]\n",
    "\n",
    "# sum by account_id\n",
    "df_fb_funnel = df_fb_funnel.groupby('account_id').agg(sum).reset_index()\n",
    "\n",
    "df_fb_funnel['total_engagement'] = df_fb_funnel['new_engagement'] + df_fb_funnel['tag_friend'] + df_fb_funnel['purchase_intention']\n",
    "\n",
    "df_fb_funnel = df_fb_funnel[['account_id', 'total_engagement', 'reaction', 'share', 'comment', 'tag_friend', 'purchase_intention']]\n",
    "\n",
    "# use pd.melt to change wide format to long format\n",
    "df_fb_funnel = pd.melt(df_fb_funnel, id_vars='account_id', value_vars=['total_engagement', 'reaction', 'share', 'comment', 'tag_friend', 'purchase_intention'], var_name='type')\n",
    "\n",
    "\n",
    "\n",
    "# merge with account_display_name\n",
    "df_fb_funnel = df_fb_funnel.merge(df_acc, left_on='account_id', right_on='account_id', how='left')\n",
    "\n",
    "# change 'type' column to be categorical type in order to sort value.\n",
    "funnel_cats = ['total_engagement', 'reaction', 'share', 'comment', 'tag_friend', 'purchase_intention']\n",
    "from pandas.api.types import CategoricalDtype\n",
    "funnel_type = CategoricalDtype(categories=funnel_cats, ordered=True)\n",
    "df_fb_funnel['type'] = df_fb_funnel['type'].astype(funnel_type)\n",
    "df_fb_funnel = df_fb_funnel.sort_values(by=['account_id', 'type'])\n",
    "\n",
    "# merge with category and fanrage\n",
    "df_fb_funnel = df_fb_funnel.merge(right=df_cat_fanrange[['account_display_name', 'category', 'fan_range']], left_on='account_display_name', right_on='account_display_name', how='inner')\n",
    "\n",
    "\n",
    "# export to csv\n",
    "df_fb_funnel.to_csv('df_fb_funnel.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253295 entries, 0 to 253294\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   index                 253295 non-null  int64         \n",
      " 1   post_id               253295 non-null  object        \n",
      " 2   channel               253295 non-null  object        \n",
      " 3   account_id            253295 non-null  object        \n",
      " 4   account_username      253295 non-null  object        \n",
      " 5   account_display_name  253295 non-null  object        \n",
      " 6   link                  253295 non-null  object        \n",
      " 7   created_at            253295 non-null  datetime64[ns]\n",
      " 8   message               253295 non-null  object        \n",
      " 9   favorite              253295 non-null  int64         \n",
      " 10  retweet               253295 non-null  int64         \n",
      " 11  share_on_facebook     253295 non-null  int64         \n",
      " 12  engagement            253295 non-null  int64         \n",
      " 13  reply                 253295 non-null  int64         \n",
      " 14  positive              253295 non-null  int64         \n",
      " 15  neutral               253295 non-null  int64         \n",
      " 16  negative              253295 non-null  int64         \n",
      " 17  fan                   253295 non-null  int64         \n",
      " 18  new_engagement        253295 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(11), object(7)\n",
      "memory usage: 36.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# function to print all the hashtags in a text\n",
    "def extract_hashtags(text):\n",
    "     \n",
    "    # the regular expression\n",
    "    regex = \"#[(\\w)|\\u0E00-\\u0E7F]+\" \n",
    "     \n",
    "    # extracting the hashtags\n",
    "    hashtag_list = re.findall(regex, text)\n",
    "    \n",
    "    return hashtag_list   \n",
    "\n",
    "def get_hashtags(rown):\n",
    "    # Check is nan     \n",
    "    if(rown['message'] != rown['message']):\n",
    "        rown['message'] = \"\"\n",
    "    return extract_hashtags(rown['message'])\n",
    "\n",
    "def get_count_frequency(df,column):\n",
    "    freq_dict = {}\n",
    "    for rown in df[column]:\n",
    "        for hashtags in rown:\n",
    "            if (hashtags in freq_dict):\n",
    "                freq_dict[hashtags] += 1\n",
    "            else:\n",
    "                freq_dict[hashtags] = 1\n",
    "    return freq_dict\n",
    "\n",
    "twitter_df = df_tw.reset_index()\n",
    "\n",
    "twitter_df.info()\n",
    "twitter_df.count()\n",
    "twitter_df.shape\n",
    "\n",
    "twitter_df['hashtags'] = np.empty((len(twitter_df), 0)).tolist()\n",
    "twitter_df['hashtags'] = twitter_df.apply(get_hashtags,axis=1)\n",
    "hashtags_dict = get_count_frequency(twitter_df,'hashtags')\n",
    "hashtags_df = pd.DataFrame(\n",
    "    {'hashtags': list(hashtags_dict.keys()),\n",
    "     'total': list(hashtags_dict.values())\n",
    "    })\n",
    "hashtags_df[hashtags_df['total'] > 50].sort_values(by=['total'], ascending=False).head(5)\n",
    "hashtags_df[hashtags_df['total'] > 50].sort_values(by=['total'], ascending=False).to_csv(\"twitter_hashtags.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
